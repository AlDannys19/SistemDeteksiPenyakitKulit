{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "819d0f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Border Irregularity: 2.6609176995254495\n",
      "Color Variegation: 0.253918161691393\n",
      "Mean R: 43.995196906887756, Std R: 74.40092288581273\n",
      "Mean G: 39.75896843112245, Std G: 70.01274326030816\n",
      "Mean B: 20.713608099489797, Std B: 35.28761894021951\n",
      "Diameter: 5.021904708862305\n",
      "Asymmetry: 0.8055054151624549\n",
      "Predicted Class: 5\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def extract_contour(color_image):\n",
    "    hsv_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2HSV)\n",
    "    lower_green = np.array([35, 100, 100])\n",
    "    upper_green = np.array([85, 255, 255])\n",
    "    mask = cv2.inRange(hsv_image, lower_green, upper_green)\n",
    "    return mask\n",
    "\n",
    "def calculate_border_irregularity(color_image):\n",
    "    mask = extract_contour(color_image)\n",
    "    blurred = cv2.GaussianBlur(mask, (5, 5), 0)\n",
    "    contours, _ = cv2.findContours(blurred, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    perimeter = cv2.arcLength(largest_contour, True)\n",
    "    area = cv2.contourArea(largest_contour)\n",
    "    if area == 0:\n",
    "        return None\n",
    "    border_irregularity = perimeter ** 2 / (4 * np.pi * area)\n",
    "    return border_irregularity\n",
    "\n",
    "def calculate_color_variegation(image):\n",
    "    lesion_r = image[:, :, 2]\n",
    "    lesion_g = image[:, :, 1]\n",
    "    lesion_b = image[:, :, 0]\n",
    "    mean_r = np.mean(lesion_r)\n",
    "    std_r = np.std(lesion_r)\n",
    "    mean_g = np.mean(lesion_g)\n",
    "    std_g = np.std(lesion_g)\n",
    "    mean_b = np.mean(lesion_b)\n",
    "    std_b = np.std(lesion_b)\n",
    "    C_r = std_r / np.max(lesion_r) if np.max(lesion_r) != 0 else 0\n",
    "    C_g = std_g / np.max(lesion_g) if np.max(lesion_g) != 0 else 0\n",
    "    C_b = std_b / np.max(lesion_b) if np.max(lesion_b) != 0 else 0\n",
    "    avg_color_variegation = (C_r + C_g + C_b) / 3\n",
    "    return avg_color_variegation, mean_r, std_r, mean_g, std_g, mean_b, std_b\n",
    "\n",
    "def calculate_diameter(image, dpi=1200):\n",
    "    mask = extract_contour(image)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) == 0:\n",
    "        return 0\n",
    "    max_contour = max(contours, key=cv2.contourArea)\n",
    "    _, radius = cv2.minEnclosingCircle(max_contour)\n",
    "    diameter_pixels = 2 * radius\n",
    "    diameter_physical = diameter_pixels * (25.4 / dpi)\n",
    "    return diameter_physical\n",
    "\n",
    "def calculate_asymmetry(binary_image):\n",
    "    binary_image = binary_image.astype(bool)\n",
    "    horizontal_flip = np.fliplr(binary_image)\n",
    "    diff_horizontal = binary_image & ~horizontal_flip\n",
    "    vertical_flip = np.flipud(binary_image)\n",
    "    diff_vertical = binary_image & ~vertical_flip\n",
    "    diff_horizontal_area = np.count_nonzero(diff_horizontal)\n",
    "    diff_vertical_area = np.count_nonzero(diff_vertical)\n",
    "    area_total = np.count_nonzero(binary_image)\n",
    "    if area_total == 0:\n",
    "        return 0\n",
    "    asymm_idx = ((diff_horizontal_area / area_total) + (diff_vertical_area / area_total)) / 2\n",
    "    return asymm_idx\n",
    "\n",
    "def predict_class(features, model_path, scaler_path):\n",
    "    try:\n",
    "        svm_model = joblib.load(model_path)\n",
    "        scaler = joblib.load(scaler_path)\n",
    "        features_scaled = scaler.transform([features])\n",
    "        predicted_class = svm_model.predict(features_scaled)\n",
    "        return predicted_class[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error in predict_class: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Path gambar input\n",
    "input_image = r\"C:\\Users\\Danny\\Skripsi\\Dataset\\data 2\\restored_images_with_contours\\mel\\_56_3948599.jpg\"\n",
    "\n",
    "# Menghitung fitur-fitur dari gambar\n",
    "image = cv2.imread(input_image)\n",
    "if image is None:\n",
    "    print(f\"Error: Unable to read image '{input_image}'\")\n",
    "else:\n",
    "    border_irregularity = calculate_border_irregularity(image)\n",
    "    color_variegation, mean_r, std_r, mean_g, std_g, mean_b, std_b = calculate_color_variegation(image)\n",
    "    diameter = calculate_diameter(image)\n",
    "    binary_image = extract_contour(image)\n",
    "    asymmetry = calculate_asymmetry(binary_image)\n",
    "\n",
    "    # Ensure no feature is None\n",
    "    if None in [border_irregularity, color_variegation, diameter, asymmetry]:\n",
    "        print(\"Error: One or more features could not be calculated.\")\n",
    "    else:\n",
    "        # Menampilkan nilai dari tiap fitur\n",
    "        print(f\"Border Irregularity: {border_irregularity}\")\n",
    "        print(f\"Color Variegation: {color_variegation}\")\n",
    "        print(f\"Mean R: {mean_r}, Std R: {std_r}\")\n",
    "        print(f\"Mean G: {mean_g}, Std G: {std_g}\")\n",
    "        print(f\"Mean B: {mean_b}, Std B: {std_b}\")\n",
    "        print(f\"Diameter: {diameter}\")\n",
    "        print(f\"Asymmetry: {asymmetry}\")\n",
    "\n",
    "        features = np.array([\n",
    "            border_irregularity,\n",
    "            color_variegation,\n",
    "            mean_r,\n",
    "            std_r,\n",
    "            mean_g,\n",
    "            std_g,\n",
    "            mean_b,\n",
    "            std_b,\n",
    "            diameter,\n",
    "            asymmetry\n",
    "        ])\n",
    "\n",
    "        # Path model SVM (file joblib)\n",
    "        svm_model_path = r\"C:\\Users\\Danny\\Skripsi\\Dataset\\data 2\\file csv\\svm.joblib\"\n",
    "        scaler_path = r\"C:\\Users\\Danny\\Skripsi\\Dataset\\data 2\\file csv\\scaler.joblib\"\n",
    "\n",
    "        predicted_class = predict_class(features, svm_model_path, scaler_path)\n",
    "        print(f\"Predicted Class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d8d7d507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class                  0\n",
      "Asymmetry              0\n",
      "Border Irregularity    0\n",
      "Color Variegation      0\n",
      "Diameter               0\n",
      "Mean R                 0\n",
      "Std R                  0\n",
      "Mean G                 0\n",
      "Std G                  0\n",
      "Mean B                 0\n",
      "Std B                  0\n",
      "dtype: int64\n",
      "Scaler saved to C:\\Users\\Danny\\Skripsi\\Dataset\\data 2\\file csv\\scaler.pkl\n",
      "Accuracy: 0.7463091482649842\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          df       0.77      0.79      0.78      2232\n",
      "          nv       0.81      0.90      0.85      2477\n",
      "         mel       0.65      0.66      0.65      2968\n",
      "        vasc       0.87      0.90      0.88      2570\n",
      "         bkl       0.64      0.56      0.59      2985\n",
      "       akiec       0.76      0.74      0.75      2618\n",
      "\n",
      "    accuracy                           0.75     15850\n",
      "   macro avg       0.75      0.76      0.75     15850\n",
      "weighted avg       0.74      0.75      0.74     15850\n",
      "\n",
      "Model saved to C:\\Users\\Danny\\Skripsi\\Dataset\\data 2\\file csv\\svm.pkl\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pickle\n",
    "\n",
    "# Path file CSV\n",
    "file_path = r\"C:\\Users\\Danny\\Skripsi\\Dataset\\data 2\\file csv\\coba\\test.csv\"\n",
    "\n",
    "# Baca dataset dari file CSV\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Mapping kelas ke nilai numerik\n",
    "class_map = {'df': 0, 'nv': 1, 'mel': 2, 'vasc': 3, 'bkl': 5, 'akiec': 6}\n",
    "df['Class'] = df['Class'].map(class_map)\n",
    "\n",
    "# Pisahkan fitur (X) dan target (y)\n",
    "X = df.drop('Class', axis=1).values\n",
    "y = df['Class'].values\n",
    "\n",
    "print(df.isnull().sum())  # Pemeriksaan nilai NaN di DataFrame\n",
    "\n",
    "# Bagi dataset menjadi data latih dan data uji\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# Skalakan fitur menggunakan StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Simpan StandardScaler ke dalam file menggunakan pickle\n",
    "scaler_file_path = r\"C:\\Users\\Danny\\Skripsi\\Dataset\\data 2\\file csv\\scaler.pkl\"\n",
    "with open(scaler_file_path, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(f\"Scaler saved to {scaler_file_path}\")\n",
    "\n",
    "# Inisialisasi model SVM dengan kernel RBF\n",
    "model = SVC(kernel='rbf', C=10, gamma=1)\n",
    "\n",
    "# Latih model menggunakan data latih\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediksi kelas untuk data uji\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluasi model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=class_map.keys()))\n",
    "\n",
    "# Simpan model ke dalam file menggunakan pickle\n",
    "model_file_path = r\"C:\\Users\\Danny\\Skripsi\\Dataset\\data 2\\file csv\\svm.pkl\"\n",
    "with open(model_file_path, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(f\"Model saved to {model_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "422207c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribusi kelas sebelum undersampling:\n",
      "bkl      5920\n",
      "mel      5920\n",
      "vasc     5290\n",
      "akiec    5209\n",
      "nv       4949\n",
      "df       4410\n",
      "Name: Class, dtype: int64\n",
      "Distribusi kelas setelah undersampling:\n",
      "akiec    4410\n",
      "bkl      4410\n",
      "df       4410\n",
      "mel      4410\n",
      "nv       4410\n",
      "vasc     4410\n",
      "Name: Class, dtype: int64\n",
      "Data yang sudah di-undersampling telah disimpan ke 'C:\\Users\\Danny\\Skripsi\\Dataset\\data 2\\file csv\\coba\\test_undersampled.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Membaca data dari file CSV\n",
    "file_path = r\"C:\\Users\\Danny\\Skripsi\\Dataset\\data 2\\file csv\\coba\\test.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Menghapus duplikat data\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# Menampilkan distribusi kelas sebelum undersampling\n",
    "print(\"Distribusi kelas sebelum undersampling:\")\n",
    "print(data['Class'].value_counts())\n",
    "\n",
    "# Menentukan jumlah sampel untuk setiap kelas berdasarkan kelas dengan jumlah data terkecil\n",
    "min_class_count = data['Class'].value_counts().min()\n",
    "\n",
    "# Melakukan undersampling pada setiap kelas\n",
    "undersampled_data_list = []\n",
    "for class_value in data['Class'].unique():\n",
    "    class_subset = data[data['Class'] == class_value]\n",
    "    undersampled_class_subset = resample(class_subset,\n",
    "                                         replace=False,    # mengambil sampel tanpa penggantian\n",
    "                                         n_samples=min_class_count, # mengatur jumlah sampel sesuai dengan data minoritas\n",
    "                                         random_state=42)  # untuk keperluan reproduktif\n",
    "    undersampled_data_list.append(undersampled_class_subset)\n",
    "\n",
    "# Menggabungkan kembali data yang telah di-undersampling\n",
    "data_undersampled = pd.concat(undersampled_data_list)\n",
    "\n",
    "# Menampilkan distribusi kelas setelah undersampling\n",
    "print(\"Distribusi kelas setelah undersampling:\")\n",
    "print(data_undersampled['Class'].value_counts())\n",
    "\n",
    "# Menyimpan data yang sudah di-undersampling ke file baru\n",
    "output_file_path = r\"C:\\Users\\Danny\\Skripsi\\Dataset\\data 2\\file csv\\coba\\test_undersampled.csv\"\n",
    "data_undersampled.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Data yang sudah di-undersampling telah disimpan ke '{output_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a196d711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.68      0.70      0.69      1057\n",
      "          df       0.67      0.60      0.63       877\n",
      "         mel       0.81      0.72      0.76      1183\n",
      "          nv       0.82      0.97      0.89       971\n",
      "        vasc       0.81      0.82      0.82      1068\n",
      "\n",
      "    accuracy                           0.76      5156\n",
      "   macro avg       0.76      0.76      0.76      5156\n",
      "weighted avg       0.76      0.76      0.76      5156\n",
      "\n",
      "Predicted class for example data: ['vasc']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib  # untuk versi scikit-learn <= 0.23\n",
    "# from joblib import load, dump  # untuk versi scikit-learn >= 0.24\n",
    "\n",
    "# Membaca dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\Danny\\Skripsi\\Dataset\\data 2\\file csv\\testku.csv\")\n",
    "\n",
    "# Memisahkan fitur dan target\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# Split data menjadi data latih dan data uji\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Skala fitur-fitur\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Melatih model SVM\n",
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prediksi menggunakan data uji\n",
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluasi model\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Simpan model ke dalam file tanpa menggunakan pickle\n",
    "joblib.dump(svm_model, 'svm_model.joblib')\n",
    "\n",
    "# Memuat kembali model\n",
    "loaded_model = joblib.load('svm_model.joblib')\n",
    "\n",
    "# Contoh penggunaan model yang telah dimuat kembali\n",
    "# Misalnya, prediksi untuk satu contoh baru\n",
    "example_data = X_test.iloc[[0]]\n",
    "example_data_scaled = scaler.transform(example_data)\n",
    "predicted_class = loaded_model.predict(example_data_scaled)\n",
    "print(f\"Predicted class for example data: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "226943d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          df       0.80      0.87      0.83       859\n",
      "         mel       0.88      0.73      0.80      1208\n",
      "          nv       0.83      0.97      0.90       988\n",
      "        vasc       0.84      0.82      0.83      1060\n",
      "\n",
      "    accuracy                           0.84      4115\n",
      "   macro avg       0.84      0.85      0.84      4115\n",
      "weighted avg       0.84      0.84      0.84      4115\n",
      "\n",
      "Predicted class for example data: ['vasc']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# Membaca dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\Danny\\Skripsi\\Dataset\\data 2\\file csv\\test.csv\")\n",
    "\n",
    "# Memisahkan fitur dan target\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# Split data menjadi data latih dan data uji\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Skala fitur-fitur\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Melatih model SVM\n",
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prediksi menggunakan data uji\n",
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluasi model\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Simpan model ke dalam file tanpa menggunakan pickle\n",
    "joblib.dump(svm_model, 'svm_model.joblib')\n",
    "\n",
    "# Memuat kembali model\n",
    "loaded_model = joblib.load('svm_model.joblib')\n",
    "\n",
    "# Contoh penggunaan model yang telah dimuat kembali\n",
    "# Misalnya, prediksi untuk satu contoh baru\n",
    "example_data = X_test.iloc[[0]]\n",
    "example_data_scaled = scaler.transform(example_data)\n",
    "predicted_class = loaded_model.predict(example_data_scaled)\n",
    "print(f\"Predicted class for example data: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "20e8fc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Border Irregularity: 1.5087183734739686\n",
      "Color Variegation: 0.2955052219996837\n",
      "Mean R: 41.17261240433673, Std R: 72.29918997866704\n",
      "Mean G: 28.622229751275512, Std G: 58.69046734801325\n",
      "Mean B: 27.443538743622447, Std B: 47.99713749977645\n",
      "Diameter: 3.1974711736043293\n",
      "Asymmetry: 0.8674179648657607\n",
      "Predicted Class: 3\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def extract_contour(color_image):\n",
    "    hsv_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2HSV)\n",
    "    lower_green = np.array([35, 100, 100])\n",
    "    upper_green = np.array([85, 255, 255])\n",
    "    mask = cv2.inRange(hsv_image, lower_green, upper_green)\n",
    "    return mask\n",
    "\n",
    "def calculate_border_irregularity(color_image):\n",
    "    mask = extract_contour(color_image)\n",
    "    blurred = cv2.GaussianBlur(mask, (5, 5), 0)\n",
    "    contours, _ = cv2.findContours(blurred, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    perimeter = cv2.arcLength(largest_contour, True)\n",
    "    area = cv2.contourArea(largest_contour)\n",
    "    if area == 0:\n",
    "        return None\n",
    "    border_irregularity = perimeter ** 2 / (4 * np.pi * area)\n",
    "    return border_irregularity\n",
    "\n",
    "def calculate_color_variegation(image):\n",
    "    lesion_r = image[:, :, 2]\n",
    "    lesion_g = image[:, :, 1]\n",
    "    lesion_b = image[:, :, 0]\n",
    "    mean_r = np.mean(lesion_r)\n",
    "    std_r = np.std(lesion_r)\n",
    "    mean_g = np.mean(lesion_g)\n",
    "    std_g = np.std(lesion_g)\n",
    "    mean_b = np.mean(lesion_b)\n",
    "    std_b = np.std(lesion_b)\n",
    "    C_r = std_r / np.max(lesion_r) if np.max(lesion_r) != 0 else 0\n",
    "    C_g = std_g / np.max(lesion_g) if np.max(lesion_g) != 0 else 0\n",
    "    C_b = std_b / np.max(lesion_b) if np.max(lesion_b) != 0 else 0\n",
    "    avg_color_variegation = (C_r + C_g + C_b) / 3\n",
    "    return avg_color_variegation, mean_r, std_r, mean_g, std_g, mean_b, std_b\n",
    "\n",
    "def calculate_diameter(image, dpi=1200):\n",
    "    mask = extract_contour(image)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) == 0:\n",
    "        return 0\n",
    "    max_contour = max(contours, key=cv2.contourArea)\n",
    "    _, radius = cv2.minEnclosingCircle(max_contour)\n",
    "    diameter_pixels = 2 * radius\n",
    "    diameter_physical = diameter_pixels * (25.4 / dpi)\n",
    "    return diameter_physical\n",
    "\n",
    "def calculate_asymmetry(binary_image):\n",
    "    binary_image = binary_image.astype(bool)\n",
    "    horizontal_flip = np.fliplr(binary_image)\n",
    "    diff_horizontal = binary_image & ~horizontal_flip\n",
    "    vertical_flip = np.flipud(binary_image)\n",
    "    diff_vertical = binary_image & ~vertical_flip\n",
    "    diff_horizontal_area = np.count_nonzero(diff_horizontal)\n",
    "    diff_vertical_area = np.count_nonzero(diff_vertical)\n",
    "    area_total = np.count_nonzero(binary_image)\n",
    "    if area_total == 0:\n",
    "        return 0\n",
    "    asymm_idx = ((diff_horizontal_area / area_total) + (diff_vertical_area / area_total)) / 2\n",
    "    return asymm_idx\n",
    "\n",
    "def predict_class(features, model_path, scaler_path):\n",
    "    try:\n",
    "        with open(model_path, 'rb') as f:\n",
    "            svm_model = pickle.load(f)\n",
    "        with open(scaler_path, 'rb') as f:\n",
    "            scaler = pickle.load(f)\n",
    "        \n",
    "        features_scaled = scaler.transform([features])\n",
    "        predicted_class = svm_model.predict(features_scaled)\n",
    "        return predicted_class[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error in predict_class: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Path gambar input\n",
    "input_image = r\"C:\\Users\\Danny\\Skripsi\\Dataset\\data 2\\restored_images_with_contours\\vasc\\_0_278127.jpg\"\n",
    "\n",
    "# Menghitung fitur-fitur dari gambar\n",
    "image = cv2.imread(input_image)\n",
    "if image is None:\n",
    "    print(f\"Error: Unable to read image '{input_image}'\")\n",
    "else:\n",
    "    border_irregularity = calculate_border_irregularity(image)\n",
    "    color_variegation, mean_r, std_r, mean_g, std_g, mean_b, std_b = calculate_color_variegation(image)\n",
    "    diameter = calculate_diameter(image)\n",
    "    binary_image = extract_contour(image)\n",
    "    asymmetry = calculate_asymmetry(binary_image)\n",
    "\n",
    "    # Ensure no feature is None\n",
    "    if None in [border_irregularity, color_variegation, diameter, asymmetry]:\n",
    "        print(\"Error: One or more features could not be calculated.\")\n",
    "    else:\n",
    "        # Menampilkan nilai dari tiap fitur\n",
    "        print(f\"Border Irregularity: {border_irregularity}\")\n",
    "        print(f\"Color Variegation: {color_variegation}\")\n",
    "        print(f\"Mean R: {mean_r}, Std R: {std_r}\")\n",
    "        print(f\"Mean G: {mean_g}, Std G: {std_g}\")\n",
    "        print(f\"Mean B: {mean_b}, Std B: {std_b}\")\n",
    "        print(f\"Diameter: {diameter}\")\n",
    "        print(f\"Asymmetry: {asymmetry}\")\n",
    "\n",
    "        features = np.array([\n",
    "            asymmetry,\n",
    "            border_irregularity,\n",
    "            color_variegation,\n",
    "            diameter,\n",
    "            mean_r,\n",
    "            std_r,\n",
    "            mean_g,\n",
    "            std_g,\n",
    "            mean_b,\n",
    "            std_b,\n",
    "        ])\n",
    "\n",
    "        # Path model SVM (file pickle)\n",
    "        svm_model_path = r\"C:\\Users\\Danny\\Skripsi\\Dataset\\data 2\\file csv\\svm.pkl\"\n",
    "        scaler_path = r\"C:\\Users\\Danny\\Skripsi\\Dataset\\data 2\\file csv\\scaler.pkl\"\n",
    "\n",
    "        predicted_class = predict_class(features, svm_model_path, scaler_path)\n",
    "        print(f\"Predicted Class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d79dd39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gambar setelah inpainting:\n",
      "[[ 6  7  8]\n",
      " [11 10  9]\n",
      " [13 30 22]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Membuat array gambar\n",
    "src = np.array([\n",
    "    [6,  7,  8],\n",
    "    [11, 0,  9],\n",
    "    [13, 30, 22]\n",
    "], dtype=np.uint8)\n",
    "\n",
    "# Membuat mask biner\n",
    "mask = np.array([\n",
    "    [0, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 0]\n",
    "], dtype=np.uint8)\n",
    "\n",
    "# Melakukan inpainting dengan metode Telea\n",
    "dst = cv2.inpaint(src, mask, 1, cv2.INPAINT_TELEA)\n",
    "\n",
    "print(\"Gambar setelah inpainting:\")\n",
    "print(dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823d5f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c1acda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
